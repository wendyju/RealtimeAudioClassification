{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:25.120376Z",
     "start_time": "2020-08-02T21:29:25.114187Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:25.860651Z",
     "start_time": "2020-08-02T21:29:25.783158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Type=\"TRAINING\"\n",
    "exec(open(\"../helperFunctions.py\",\"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:41.596014Z",
     "start_time": "2020-08-02T21:29:41.590541Z"
    }
   },
   "outputs": [],
   "source": [
    "UsedClasses=[]\n",
    "for k in widgetDict:\n",
    "    if widgetDict[k].value==True:\n",
    "        UsedClasses.append(k)\n",
    "if(len(UsedClasses)<2):\n",
    "    print(\"Something is wrong here. we need at least 2 classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data set\n",
    "If test set is not defined previously, this function pulls a test set from the training set using a 80/20%split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:44.497868Z",
     "start_time": "2020-08-02T21:29:44.446826Z"
    }
   },
   "outputs": [],
   "source": [
    "classes =  tuple(UsedClasses)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainSets=[]\n",
    "testSets=[]\n",
    "\n",
    "for cl in classes:   \n",
    "    trainPath=os.path.join(SPECTRUM_IMAGES_ROOT,cl,'train')\n",
    "    if os.path.isdir (trainPath):\n",
    "        trainSets.append(SpectrumDataset(classes.index(cl),trainPath,transform))\n",
    "    else:\n",
    "        print('Coud not find path',trainPath);\n",
    "    \n",
    "    testPath=os.path.join(SPECTRUM_IMAGES_ROOT,cl,'test')\n",
    "    if os.path.isdir (testPath):\n",
    "        testSets.append(SpectrumDataset(classes.index(cl),testPath,transform))\n",
    "    else:\n",
    "        print('Coud not find path',testPath);\n",
    "\n",
    "\n",
    "lowestItemCount=np.inf\n",
    "classID=None\n",
    "for i,train in enumerate(trainSets):\n",
    "    if(lowestItemCount>len(train)):\n",
    "        lowestItemCount=len(train)\n",
    "        classID=i\n",
    "        lowestItemCount=len(train)\n",
    "for i in range(len(trainSets)):\n",
    "    trainSets[i].ReduceSize(lowestItemCount)\n",
    "    \n",
    "\n",
    "TrainDataSet = torch.utils.data.ConcatDataset(trainSets)\n",
    "TestDataSet = torch.utils.data.ConcatDataset(testSets)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(TrainDataSet, batch_size=16, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(TestDataSet, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview sample training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes an entire training batch of images and displays them with their respective labels. Have a look and verify that indeed you see spectrograph images that look similar to what you saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:11.509950Z",
     "start_time": "2020-08-02T20:42:09.463804Z"
    }
   },
   "outputs": [],
   "source": [
    "#Getting some random training images and showing them\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "for i in range(trainloader.batch_size):\n",
    "    imshow(images[i])\n",
    "    print(classes[labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify use of Graphics Card (if there is one) and use ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:11.649015Z",
     "start_time": "2020-08-02T20:42:11.511342Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model \n",
    "The model '../Models/MainModelUrban.pth' was trained on the UrbanSound dataset; other models could be specified instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:36:02.653653Z",
     "start_time": "2020-08-02T20:36:02.539338Z"
    }
   },
   "outputs": [],
   "source": [
    "ModelData = torch.load('../Models/MainModelUrban.pth',map_location='cpu')\n",
    "model.load_state_dict(ModelData['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting off the head\n",
    "In the following cell, the setting 'param.requires_grad = False' is **the** function that is telling the network to only retrain the last layer. If you set this parameter to True, the training will take much longer, but hopefully be better at predicting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:16.669357Z",
     "start_time": "2020-08-02T20:42:16.661468Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For each parameter in the network we turn of training, \n",
    "by setting  .requires_grad  to `False`.\n",
    "\n",
    "This makes sure that the computer will not try to adjust thos variables when \"training\".\n",
    "'''\n",
    "for param in model.parameters(): #\n",
    "    param.requires_grad = False #... \n",
    "    \n",
    "'''\n",
    "'fc' stands for \"fully connected\" and it is the very last layer in the neural net.\n",
    "We replace this layer with a new fully connected layer, that connects the 512 input neurons to neurons for our classes.\n",
    "'''    \n",
    "model.fc = nn.Linear(512, len(classes)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move model to GPU (if there is a GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:23.491845Z",
     "start_time": "2020-08-02T20:42:23.481809Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train_epoch_losses=[]\n",
    "test_epoch_losses=[]\n",
    "epoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:19.660275Z",
     "start_time": "2020-08-02T20:42:19.657733Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, len(classes)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:00.245670Z",
     "start_time": "2020-08-02T20:42:29.699734Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training the network on the training dataset\n",
    "for i in range(20):  # loop over the dataset multiple (5) times \n",
    "    epoch+=1\n",
    "    print(\"Starting epoch:\",epoch)\n",
    "    epochLoss=0.0\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #print(\"Running Batches\",i)\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        if device.type=='cuda':\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        if((i+i)%200==0):\n",
    "            if(i>0):\n",
    "                print('Processed images:',i*trainloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epochLoss+=loss.item()\n",
    "        \n",
    "    \n",
    "    model.eval()\n",
    "    testLoss=0\n",
    "    print(\"About to test the performance on the test set.\")\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            if device.type=='cuda':\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            testLoss+=loss.item()\n",
    "            if(i%50==0):\n",
    "                if(i>0):\n",
    "                    print('Tested images:',i*testloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "\n",
    "\n",
    "    train_epoch_losses.append(epochLoss/len(trainloader))\n",
    "    test_epoch_losses.append(testLoss/len(testloader))\n",
    "    EpochLength = time.time()-t0\n",
    "    print('{} train loss: {:.3f} and test loss: {:.3f}, and it took us: {:.2f} seconds.'.format (epoch + 1, epochLoss / len(trainloader),testLoss/len(testloader),EpochLength))  # DAVID CHanged it to 1000 from 2000 not sure if thats totally done\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post training analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training has finished, save information about the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:08.058441Z",
     "start_time": "2020-08-02T20:44:07.767189Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving the learnd model in file that can be loaded in for inference\n",
    "torch.save({\n",
    "    'model':model.state_dict(),\n",
    "    'classes':classes,\n",
    "    'resolution':224,\n",
    "    'modelType':\"resnet18\" # <= If you try out different models make sure to change this too\n",
    "},\"../models/CatDogResNet.pth\") # <=Edit file name here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display how the traing and test loss progressed over successive epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:09.700714Z",
     "start_time": "2020-08-02T20:44:09.070817Z"
    }
   },
   "outputs": [],
   "source": [
    "#Displaying how the loss progresses over time.\n",
    "plt.plot(train_epoch_losses, label='Training Loss',c='r')\n",
    "plt.plot(test_epoch_losses, label='Test Loss',c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show spectagrams, Predicted and Actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:12.759024Z",
     "start_time": "2020-08-02T20:44:12.697637Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print predicted and acual labels for Spectragrams\n",
    "dataiter = iter(testloader)\n",
    "model.eval()\n",
    "for j in range (2):\n",
    "    images, labels = dataiter.next()\n",
    "    if device == 'cuda':\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        imshow(images[i])\n",
    "        print('GroundTruth: ',classes[labels[i]])\n",
    "        print('Predicted: ',  classes[predicted[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracy of test predictions for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:15.905168Z",
     "start_time": "2020-08-02T20:44:14.974999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Network analytics\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "model.eval()\n",
    "allLabels=[]\n",
    "allPrediction=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        if (c.dim()==0):\n",
    "            continue\n",
    "        for i in range(testloader.batch_size):\n",
    "            if(len(labels)<=i):\n",
    "                continue;\n",
    "            label = labels[i]\n",
    "            allLabels.append(labels[i].to('cpu').numpy())\n",
    "            allPrediction.append(predicted[i].to('cpu').numpy())\n",
    "            #print (c.shape)\n",
    "            if(testloader.batch_size>1):\n",
    "\n",
    "                class_correct[label] += c[i].item()\n",
    "            else:\n",
    "                class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(confusion_matrix(allLabels, allPrediction))\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
